---
#- name: TC Timeliness Tests of Statistical Classifier

#*** Version 0.1.1

#*** Pass variables on the command line to determine the test type:
#
#*** Example nmeta baseline:
#***   ansible-playbook ~/automated_tests/tc-timely-noload-statistical-template.yml --extra-vars "start_nmeta=true start_nmeta2=false duration=10 results_dir=~/results/timeliness/statistical/ policy_name=main_policy_regression_statistical.yaml"

#*** Set up the results timestamp
- hosts: clients

  tasks:

    - name: Kill any running Iperf processes
      command: "sudo pkill -f iperf"
      ignore_errors: True

    - name: Generate global results timestamp variable
      local_action: shell date +%Y%m%d%H%M%S
      register: results_timestamp
      run_once: true

    - debug: msg="Result folder will be {{ results_dir }}{{ results_timestamp.stdout }}"

    - debug: msg="Creating local and remote result folders..."

    - name: Create local results folder
      local_action: shell mkdir {{ results_dir }}{{ results_timestamp.stdout }}
      register: create_local_results_folder
      run_once: true

    - name: Create client results folder
      file: path={{ results_dir }}{{ results_timestamp.stdout }} state=directory

#*** Switch process clean-up:
- hosts: switches

  tasks:

    - name: Kill switch OpenFlow snooping
      command: "sudo pkill -f ovs-ofctl"
      ignore_errors: True

    #*** Restart Open vSwitch Services
    - name: Restart Open vSwitch Switch Service
      command: "sudo service openvswitch-switch restart"

#*** Start by ensuring nmeta is not running then start it if required:
- hosts: controllers

  tasks:

    #*** Archive the log file so that we can later just put our log
    - name: ct1 Rotate nmeta2 log
      command: "sudo mv /var/log/nmeta /var/log/nmeta.old"
      when: start_nmeta2
      ignore_errors: True

    #*** Rsyslog needs restart after moving the log file
    - name: ct1 Restart rsyslog
      command: "sudo service rsyslog restart"
      when: start_nmeta2

    - name: Kill controller ryu processes (nmeta or simple switch etc)
      command: "sudo pkill -f ryu-manager"
      ignore_errors: True

    - name: Copy identity regression main config file into place
      command: "cp ~/nmeta/config/tests/regression/{{ policy_name }} ~/nmeta/config/main_policy.yaml"
      when: start_nmeta

    - name: Copy identity regression qos config file into place
      command: "cp ~/nmeta/config/tests/regression/qos_policy_regression.yaml ~/nmeta/config/qos_policy.yaml"
      when: start_nmeta

    - name: Copy standard config file into place
      command: "cp ~/nmeta/config/tests/config_standard.yaml ~/nmeta/config/config.yaml"
      when: start_nmeta

    - name: Copy identity regression main config file into place
      command: "cp ~/nmeta2/nmeta2/config/tests/regression/{{ policy_name }} ~/nmeta2/nmeta2/config/main_policy.yaml"
      when: start_nmeta2

    - name: Copy standard config file into place
      command: "cp ~/nmeta2/nmeta2/config/tests/config_standard.yaml ~/nmeta2/nmeta2/config/config.yaml"
      when: start_nmeta2

    - name: Set PYTHONPATH environment variable
      shell: "export PYTHONPATH=~/ryu"

    - name: Run Ryu with nmeta (if required) on controller in the background
      shell: "cd ~/ryu; PYTHONPATH=. ./bin/ryu-manager ../nmeta/nmeta.py &"
      args:
        chdir: ~/ryu
      async: 90000
      poll: 0
      when: start_nmeta

    - name: Run Ryu with nmeta2 (if required) on controller in the background
      shell: "nohup ~/ryu/bin/ryu-manager ~/nmeta2/nmeta2/nmeta2.py &"
      args:
        chdir: ~/ryu
      async: 90000
      poll: 0
      when: start_nmeta2

    - name: Check nmeta is running (if required) on controller
      command: "pgrep -f nmeta.py"
      when: start_nmeta

    - name: Check nmeta2 is running (if required) on controller
      command: "pgrep -f nmeta2.py"
      when: start_nmeta2

    - name: Create server results folder
      file: path={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }} state=directory

    - name: Pause to allow time for switch to connect to controller
      pause: seconds=8
      
#*** Record start Iperf server on server and record test parameters:
- hosts: servers

  tasks:

    - name: Kill any running Iperf processes
      command: "sudo pkill -f iperf"
      ignore_errors: True

    - name: Start Iperf tcp-5555 on Server
      shell: "iperf -s -p 5555 -i 1"
      async: 90000
      poll: 0

    - name: Create server results folder
      file: path={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }} state=directory

    - name: Record input variables to file for the record
      copy: content="tc-timely-noload-statistical-template.yml was run with start_nmeta={{ start_nmeta }} start_nmeta2={{ start_nmeta2 }} duration={{ duration }} results_dir={{ results_dir }} policy_name={{ policy_name }}" dest={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/tc-timely-noload-statistical-template.yml.parameters.txt

#*** Data Plane Auxiliary Engine, when doing nmeta2:
- hosts: dpae

  tasks:

    - name: Kill nmeta2dpae processes
      command: "sudo pkill -f nmeta2dpae.py"
      ignore_errors: True
      when: start_nmeta2

    - name: Run nmeta2-dpae (if required) on dpae in the background
      #*** Note the use of redirect of output, otherwise will get broken pipe error:
      shell: "nohup sudo /home/bob/nmeta2dpae/nmeta2dpae/nmeta2dpae.py >/dev/null 2>&1 &"
      async: 90000
      poll: 0
      when: start_nmeta2

    - name: Doublecheck that nmeta2dpae.py is running
      command: "pgrep -f nmeta2dpae.py"
      when: start_nmeta2

    - name: Pause to allow time for DPAE to connect to Controller
      pause: seconds=10

    - name: Create server results folder
      file: path={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }} state=directory

    - name: DPAE sniff interface packets before test
      shell: "ifconfig eth1 | grep \"RX packets\" > {{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/{{ inventory_hostname }}-in-pkts-b4-test.txt"

    - name: Retrieve DPAE sniff interface packets
      fetch: src={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/{{ inventory_hostname }}-in-pkts-b4-test.txt dest={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/ flat=yes

#*** Set up monitoring on the switch for flow table modification timestamps:

- hosts: switches

  tasks:
    - name: Create switch results folder
      file: path={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }} state=directory

    - debug: msg="Starting switch OpenFlow snooping..."

    - name: Set up switch OpenFlow snooping
      shell: "nohup sudo ovs-ofctl snoop br0 --timestamp > {{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/{{ inventory_hostname }}-OF-snooping.txt 2>&1 &"
      async: 90000
      poll: 0

    - name: Pause to allow time for switch snooping to commence
      pause: seconds=6

#*** Run Iperf Test:

- hosts: clients

  tasks:

    #*** Bail out of test if PING fails:
    - name: send PING to server so that MAC table is current in both directions
      shell: "ping -c 1 sv1"

    - name: Pause to allow time for MAC learning
      pause: seconds=3

    #- name: run tcpdump in background for set number of packets with overview to file
    #  shell: "nohup sudo tcpdump -i eth1 -c 20 > {{ results_dir }}{{ results_timestamp.stdout }}/{{ inventory_hostname }}-tcpdump.txt 2>&1 &"
    #  async: 90000
    #  poll: 0

    - name: Run Iperf tcp-5555 test from Client
      shell: "~/testtools/tosc/tosc.py {{ results_dir }}{{ results_timestamp.stdout }}/{{ inventory_hostname }}-iperf_starttime.txt 'iperf -c sv1 -p 5555 -t {{ duration }} -y c > {{ results_dir }}{{ results_timestamp.stdout }}/{{ inventory_hostname }}-5555-iperf_result.txt' {{ results_dir }}{{ results_timestamp.stdout }}/{{ inventory_hostname }}-iperf_endtime.txt"

    - name: Retrieve Iperf start time
      fetch: src={{ results_dir }}{{ results_timestamp.stdout }}/{{ inventory_hostname }}-iperf_starttime.txt dest={{ results_dir }}{{ results_timestamp.stdout }}/ flat=yes

    - name: Retrieve Iperf end time
      fetch: src={{ results_dir }}{{ results_timestamp.stdout }}/{{ inventory_hostname }}-iperf_endtime.txt dest={{ results_dir }}{{ results_timestamp.stdout }}/ flat=yes

    - name: Retrieve Iperf results
      fetch: src={{ results_dir }}{{ results_timestamp.stdout }}/{{ inventory_hostname }}-5555-iperf_result.txt dest={{ results_dir }}{{ results_timestamp.stdout }}/ flat=yes

    #- name: Retrieve tcpdump results
    #  fetch: src={{ results_dir }}{{ results_timestamp.stdout }}/{{ inventory_hostname }}-tcpdump.txt dest={{ results_dir }}{{ results_timestamp.stdout }}/ flat=yes

#*** Get Data Plane Auxiliary Engine interface counters:
- hosts: dpae

  tasks:

    - name: DPAE sniff interface packets after test
      shell: "ifconfig eth1 | grep \"RX packets\" > {{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/{{ inventory_hostname }}-in-pkts-after-test.txt"

    - name: Retrieve DPAE sniff interface packets
      fetch: src={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/{{ inventory_hostname }}-in-pkts-after-test.txt dest={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/ flat=yes

#*** Dump and retrieve the Switch Flow Table for the record:

- hosts: switches

  tasks:

    - debug: msg="Tidying up by killing unwanted switch async processes and retrieve results..."

    - name: Kill switch OpenFlow snooping
      command: "sudo pkill -f ovs-ofctl"
      ignore_errors: True

    - name: Dump the Switch Flow Table
      shell: "sudo ovs-ofctl dump-flows br0 -O OpenFlow13 > {{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/{{ inventory_hostname }}-flows.txt"

    - name: Retrieve the Switch Flow Table
      fetch: src={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/{{ inventory_hostname }}-flows.txt dest={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/ flat=yes

    - name: Retrieve the Switch OpenFlow Snooping File
      fetch: src={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/{{ inventory_hostname }}-OF-snooping.txt dest={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/ flat=yes

#*** Retrieve file that holds parameters that test was called with:

- hosts: servers

  tasks:

    - name: Retrieve input variables file
      fetch: src={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/regression-static-template.yml.parameters.txt dest={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/ flat=yes

#*** Retrieve copy of main policy file that was used:
- hosts: controllers

  tasks:

    - name: Retrieve the main policy file
      fetch: src=~/nmeta/config/main_policy.yaml dest={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/ flat=yes
      when: start_nmeta

    - name: Retrieve the main policy file
      fetch: src=~/nmeta2/nmeta2/config/main_policy.yaml dest={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/ flat=yes
      when: start_nmeta2

#*** Stop any Ryu processes on Controller:

- hosts: controllers

  tasks:

    - name: Export tail of Controller nmeta2 App log
      shell: "tail -300 /var/log/nmeta > {{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/{{ inventory_hostname }}-applog.txt"
      when: start_nmeta2

    - name: Retrieve Controller nmeta2 App log
      fetch: src={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/{{ inventory_hostname }}-applog.txt dest={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/ flat=yes
      when: start_nmeta2

    - name: Kill controller ryu processes (nmeta or simple switch etc)
      command: "sudo pkill -f ryu-manager"
      ignore_errors: True

    - name: Retrieve the nmeta log file
      fetch: src=/var/log/nmeta dest={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/ flat=yes
      when: start_nmeta2

    #*** Run post processing on data:

    - name: run post processing on data
      local_action: shell /home/bob/automated_tests/tc_timely_data_post_processing.py {{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/
      when: start_nmeta2

#*** Data Plane Auxiliary Engine clean-up, when doing nmeta2:
- hosts: dpae

  tasks:

    - name: Export tail of DPAE log
      shell: "tail -300 /var/log/nmeta > {{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/{{ inventory_hostname }}-applog.txt"
      when: start_nmeta2

    - name: Retrieve DPAE log
      fetch: src={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/{{ inventory_hostname }}-applog.txt dest={{ results_dir }}{{ hostvars[groups['clients'][0]].results_timestamp.stdout }}/ flat=yes
      when: start_nmeta2

    - name: Kill nmeta2dpae processes
      command: "sudo pkill -f nmeta2dpae.py"
      ignore_errors: True
      when: start_nmeta2
